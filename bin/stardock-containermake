#!/usr/bin/env bash
# vim:syn=sh
### Usage:
###    stardock-containermake [--run] <container_name> <build_script> [<base_container_name>]
### --help
###
### Make or replace a container based on a build script.  When base container
### is not provided it is assumed we want to build a new base container that
### becomes the source of other containers
export DIR=$(cd $(dirname ${BASH_SOURCE[0]}) && pwd)
source "$DIR/stardock-launcher"

run_as_root_or_die
die_on_error

test -f "${build_script}"

CONTAINER_NAME="${container_name}"
LOCK_FILE=${CONTAINER_NAME}
#CONTAINER_ROOT=/var/lib/lxc/${CONTAINER_NAME}
# A race condition occurs when locking based on containername
# where multiple containers for the same order will trample
# on each other continuiously.  We are using the 'order' to
# lock so we only build once per order
#if dev_mode ;then
  #[ -z ${order} ] && LOCK_FILE=${CONTAINER_NAME} || LOCK_FILE=${order}
#fi

# Here we start a subshell so we can flock all the
# things.  Basically, we only want to be building
# against a container one-at-a-time
(
flock 200

function docker_exec() {
  docker start "${container_name}" > /dev/null \
  && docker exec \
    "${container_name}" /bin/bash -c "$@"
}

function docker_cp() {
  if [ -d "$1" ] \
  || [ -f "$1" ]; then
    docker start "${container_name}" > /dev/null \
      && docker cp "$1" "${container_name}:$2"
  fi
}

if docker images | egrep "^${container_name}$" > /dev/null; then
  warn "containermake|exists:${CONTAINER_NAME}"
  exit 0
fi

info "containermake|creating:${CONTAINER_NAME}"

# If SERVE_CONTAINERS is _not_ set - we would always want to fall back to
# default behavior (behavior before introducing container storage).  This
# probably represents a legacy machine or one not configured for container
# storage.  Either way, in both cases, we want legacy behavior.
#
# If, "SERVE_CONTAINERS" is set then we'd ONLY want to continue with
# the old code if we 'also' had BUILD_CONTAINERS set.
if [ -z "${SERVE_CONTAINERS}" ] \
|| [ -n "${BUILD_CONTAINERS}" ]; then

  # No matter what, we will need the bridge ip
  # of the docker install of this machine
  bridge_ip

  # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
  # Things we do for building a base container.  This is basically
  # a container all other containers are based on
  # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
  info "containermake|building:${CONTAINER_NAME}"
  if [ -z "${base_container_name}" ]; then

    info "containermake|base_container:${CONTAINER_NAME}"
    # Get the IP to the Docker Bridge
    docker create -it \
     -v "${STARDOCK_CACHE}":"${STARDOCK_CACHE}" \
     --add-host="localship:${BRIDGE_IP}" \
     --name "${CONTAINER_NAME}" ubuntu:trusty

    docker_exec "mkdir -p ${STARDOCK_ROOT}"
    docker_exec "mkdir -p ${STARDOCK_BIN}"
    docker_exec 'mkdir -p $(dirname '"${STARDOCK_PRIVATE_KEY}"')'
    docker_exec "mkdir -p /etc/stardock.d"

    STARDOCK_FILES_TO_CP="
      ${STARDOCK_PRIVATE_KEY}
      ${STARDOCK_ROOT}/.config
      ${STARDOCK_BIN}/stardock-git-config
      ${STARDOCK_BIN}/stardock-git-sync
      ${STARDOCK_BIN}/stardock-common
      ${STARDOCK_BIN}/stardock-defaults
      ${STARDOCK_BIN}/stardock-launcher
      ${STARDOCK_BIN}/stardock-cronner
      ${STARDOCK_BIN}/stardock-runner
      ${STARDOCK_BIN}/stardock-builder
      ${STARDOCK_BIN}/stardock-git
      ${STARDOCK_BIN}/packages
      ${STARDOCK_BIN}/docopts
      ${STARDOCK_BIN}/docopt.py
    "
    for file in $STARDOCK_FILES_TO_CP; do
      docker_cp "$file" "$file"
    done

    info "containermake|usercreation:${CONTAINER_NAME}"
    docker_exec "chmod 777 /var/log/"
    docker_exec "useradd -s /bin/bash ${STARDOCK_APP_USER} || true"
    docker_exec "adduser ${STARDOCK_APP_USER} sudo"
    docker_exec "mkdir -p /home/${STARDOCK_APP_USER}/.ssh"
    docker_exec "echo -e '${STARDOCK_APP_USER} ALL=NOPASSWD:ALL' >> /etc/sudoers"

    docker_exec "apt-get update -y"
    docker_exec 'DEBIAN_FRONTEND=noninteractive apt-get dist-upgrade -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" --force-yes'
    docker_exec 'apt-get -y install --force-yes $(< '"${STARDOCK_BIN}/packages"')'
  else
    # Get the IP to the Docker Bridge
    docker create -it \
     -v "${STARDOCK_CACHE}":"${STARDOCK_CACHE}" \
     --add-host="localship:${BRIDGE_IP}" \
     --name "${CONTAINER_NAME}" ${base_container_name}:latest

    # XXX: WE WANT TO DELETE THIS WHEN DONE DEV'ING
    ##########################################################
    # docker_exec 'mkdir -p $(dirname '"${STARDOCK_PRIVATE_KEY}"')'
    # docker_exec "mkdir -p /etc/stardock.d"
    #
    # STARDOCK_FILES_TO_CP="
    #   ${STARDOCK_PRIVATE_KEY}
    #   ${STARDOCK_ROOT}/.config
    #   ${STARDOCK_BIN}/stardock-git
    #   ${STARDOCK_BIN}/stardock-git-config
    #   ${STARDOCK_BIN}/stardock-git-sync
    #   ${STARDOCK_BIN}/stardock-common
    #   ${STARDOCK_BIN}/stardock-defaults
    #   ${STARDOCK_BIN}/stardock-launcher
    #   ${STARDOCK_BIN}/stardock-cronner
    #   ${STARDOCK_BIN}/stardock-runner
    #   ${STARDOCK_BIN}/stardock-builder
    #   ${STARDOCK_BIN}/packages
    #   ${STARDOCK_BIN}/docopts
    #   ${STARDOCK_BIN}/docopt.py
    # "
    # for file in $STARDOCK_FILES_TO_CP; do
    #   docker_cp "$file" "$file"
    # done
    ##########################################################

  fi

  # XXX: This functionality doesn't make sense if containers
  #      are built on machine that is not SERVING the container
  #      So, I'm going to leave this here but it needs to be
  #      considered at a later date
  # docker_exec "rm -rf '/etc/stardock.d'"
  # docker_cp /etc/stardock.d /etc/stardock.d
  # XXX: Legacy Starphleet Support
  # docker_exec "rm -rf '/etc/starphleet.d'"
  # docker_cp /etc/starphleet.d /etc/starphleet.d

  # Persist the HQ inside the container
  # but only if the HQ dir exists and
  # the order name is set.  If we're making
  # the base container these things might not
  # be around yet so we can skip the HQ sync
  if [ -n "${base_container_name}" ] \
  && [ -n "${order}" ]; then
    info "containermake|headquarters_sync:${CONTAINER_NAME}"
    # We want to create an HQ that we're gonna copy into
    # the container but we wanna strip out all the git
    # repos and only copy in _this_ one
    HQ_TMP_DEST="/tmp/${CONTAINER_NAME}.hq"
    mkdir -p "${HQ_TMP_DEST}"
    rsync -ra --exclude="git/" "${HEADQUARTERS_LOCAL}/" "${HQ_TMP_DEST}/"
    # Unpublished containers might not deploy code.
    if [ -d "${HEADQUARTERS_LOCAL}/${order}/git/" ]; then
      rsync -ra "${HEADQUARTERS_LOCAL}/${order}/git/" "${HQ_TMP_DEST}/${order}/git/"
    fi
    docker_cp "${HQ_TMP_DEST}" "${HEADQUARTERS_LOCAL}"
  fi

  #this is the build script for the container itself
  info "containermake|build_script_setup:${CONTAINER_NAME}"
  #start up the container, waiting for the network, and then run the container build script

  #host file updates
  docker_exec "mkdir -p /home/${STARDOCK_APP_USER}/build"
  docker_cp "${BUILDPACKS}" "/home/${STARDOCK_APP_USER}/build"
  docker_exec "chown -R ${STARDOCK_APP_USER}:${STARDOCK_APP_USER} /home/${STARDOCK_APP_USER}"

  BUILD_SCRIPT_FULL_PATH="${STARDOCK_BIN}/build_script"
  docker_cp "${build_script}" "${BUILD_SCRIPT_FULL_PATH}"
  docker_exec "chmod +x '${BUILD_SCRIPT_FULL_PATH}'"
  docker_exec "sudo -H -u ${STARDOCK_APP_USER} bash -c '${BUILD_SCRIPT_FULL_PATH}'"
fi

# TODO: Re-think Cloud storage using docker repository =)
# This code is here as opposed to somewhere else because
# we want to compress the container for S3 and/or uncompress it
# before all the network setup below
# if [ -n "${base_container_name}" ] && is_container_storage_on_s3; then
#   # If we are expected to build containers and storage is on S3
#   # then we should have a tar.gz of the container on disk or we
#   # haven't made it yet and we should.
#   warn "S3 Container Storage Detected"
#   if [ -n "${BUILD_CONTAINERS}" ] \
#   && [ ! -f "${CONTAINER_ROOT}/${CONTAINER_NAME}.tar.gz" ]; then
#     info "Stopping container to archive it"
#     lxc-stop --name ${CONTAINER_NAME} || true
#     starphleet-lxc-wait ${CONTAINER_NAME} STOPPED
#     # There are some notes about container portability here:
#     # https://stackoverflow.com/a/34194341
#     info "Archiving container for S3 - ${CONTAINER_ROOT}/${CONTAINER_NAME}.tar.gz"
#     pushd ${CONTAINER_ROOT}
#     tar --numeric-owner -czf "${CONTAINER_NAME}.tar.gz" ./*
#     popd
#   fi
#   # The order is important here.  A machine configured to serve & build
#   # containers shouldn't go fetch containers on S3 because the containers
#   # _should_ be generated locally.  Thus, we perform the check for
#   # retreiving containers after the archive above.
#   if [ -n "${SERVE_CONTAINERS}" ] \
#   && [ ! -f "${CONTAINER_ROOT}/${CONTAINER_NAME}.tar.gz" ]; then
#
#     info "Pulling container from S3"
#     mkdir -p "${CONTAINER_ROOT}"
#     pushd "${CONTAINER_ROOT}"
#
#     starphleet-s3-get-container "${CONTAINER_NAME}" || exit ${EXIT_CODE_FOR_FAILED_S3_DOWNLOADS}
#
#     # There are some notes about container portability here:
#     # https://stackoverflow.com/a/34194341
#     info "Decompressing Container"
#     tar --numeric-owner -xzf "${CONTAINER_ROOT}/${CONTAINER_NAME}.tar.gz"
#     popd
#   fi
#
#   info "Starting container again after S3 Storage Steps"
#   lxc-start --name ${CONTAINER_NAME} -d
#   starphleet-lxc-wait ${CONTAINER_NAME} RUNNING
#   lxc-attach --name ${CONTAINER_NAME} ${LXC_OPT_FOR_STDOUT} -- bash starphleet-wait-network
# fi


if [ "${run}" == "true" ]; then
  info leaving ${CONTAINER_NAME} running
else
  docker stop "${CONTAINER_NAME}"
fi

# Make our container image
DATESTAMP="$(date +d%y%m%d-d%H%M%S)"
docker commit \
  -a "Benjamin Hudgens <benjamin@benjamindavid.com>" \
  "${CONTAINER_NAME}" "${CONTAINER_NAME}:${DATESTAMP}"

docker image tag \
  "${CONTAINER_NAME}:${DATESTAMP}" \
  "${CONTAINER_NAME}:latest"

info made container ${CONTAINER_NAME}
# Remove lock file to guarantee release
rm "/var/lock/${LOCK_FILE}"
) 200>/var/lock/${LOCK_FILE}
